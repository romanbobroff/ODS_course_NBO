{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a07dd946-e061-4902-8f2e-b6dd9c624744",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "from lifetimes import BetaGeoFitter\n",
    "from lifetimes import BetaGeoBetaBinomFitter\n",
    "from lifetimes import ParetoNBDFitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d62f3df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_parent_directory():\n",
    "    list = sys.path[0].split('\\\\')[:-1]\n",
    "    return_str = ''\n",
    "    for element in list:\n",
    "        return_str += element + '/'\n",
    "    return return_str.rstrip('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5eeda686-b7c0-4bea-a22d-57b97b7894bc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "obj = pd.read_pickle(get_parent_directory()+'/data/transaction_and_features.pkl')\n",
    "cluster = pd.read_csv(get_parent_directory()+'/data/kmeans_clusters.csv')\n",
    "\n",
    "obj['purch_date'] = pd.to_datetime(obj['purch_date']).dt.date\n",
    "obj = obj[obj.is_purchase==1]\n",
    "\n",
    "# obj = obj.merge(cluster, how='left', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f2976a4-e963-4c6f-89d3-4181686fdd8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_months = 6\n",
    "max_date = obj['purch_date'].max()\n",
    "train = obj[obj['purch_date'] < max_date - pd.Timedelta(weeks=test_months * 4)]\n",
    "test = obj[obj['purch_date'] >= max_date - pd.Timedelta(weeks=test_months * 4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b872f86c-fe0f-4475-8672-1520168ff2b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Prepare train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0d1f1f0-472d-4987-be30-39bfa57f24d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_agg = train.groupby(['id']).agg({'purch_date':['nunique', 'min', 'max']}).reset_index()\n",
    "train_agg = train_agg.droplevel(0, axis=1) \n",
    "train_agg.columns = ['id', 'frequency', 'first_purch', 'last_purch']\n",
    "train_agg['recency'] = (train_agg['last_purch'] - train_agg['first_purch']).dt.days\n",
    "train_agg['T'] = (dt.date(2021, 7, 15) - train_agg['first_purch']).dt.days\n",
    "train_agg = train_agg[['id', 'frequency', 'recency', 'T']]\n",
    "\n",
    "train_agg = train_agg.merge(cluster, how='left', on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "442dc530-6e3d-479f-a4f3-bb2bbd873066",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>frequency</th>\n",
       "      <th>recency</th>\n",
       "      <th>T</th>\n",
       "      <th>label_kmeans_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>---XA7L5SsGM0hs7WKhOag</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>246</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--16sRpjRAm2ByER7Vr7dw</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--8eSKd-Tjq2_XwPxuSZoA</td>\n",
       "      <td>2</td>\n",
       "      <td>223</td>\n",
       "      <td>440</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--AArGC6TB6ehz1u7KpFcA</td>\n",
       "      <td>17</td>\n",
       "      <td>519</td>\n",
       "      <td>919</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--GwShaESDOI3t_wT4mmDQ</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>412</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id  frequency  recency    T  label_kmeans_10\n",
       "0  ---XA7L5SsGM0hs7WKhOag          1        0  246                1\n",
       "1  --16sRpjRAm2ByER7Vr7dw          1        0   95                7\n",
       "2  --8eSKd-Tjq2_XwPxuSZoA          2      223  440                3\n",
       "3  --AArGC6TB6ehz1u7KpFcA         17      519  919                3\n",
       "4  --GwShaESDOI3t_wT4mmDQ          1        0  412                2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_agg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2da6875-4f47-4955-984b-9fd60095030d",
   "metadata": {},
   "source": [
    "## Prepare test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4a2de10-c2e7-48bd-bf65-b111d6718a44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_ext = pd.concat([test, train[train.id.isin(test.id.unique().tolist())]])\n",
    "\n",
    "min_date_test = test_ext.groupby(['id']).purch_date.min().reset_index()\n",
    "min_date_test.columns = ['id',   'min_date']\n",
    "purch_before = test_ext[test_ext.purch_date<=dt.date(2021,7,15)].groupby(['id']).purch_date.nunique().reset_index()\n",
    "test_ext = test_ext[['id',  'purch_date']].drop_duplicates()\n",
    "test_ext.sort_values(by=['id',   'purch_date'], inplace=True) \n",
    "test_ext['prev_purch_date'] = test_ext.groupby(['id']).purch_date.shift()\n",
    "test_ext = test_ext[test_ext.purch_date>dt.date(2021,7,15)]\n",
    "\n",
    "test_ext = test_ext.merge(min_date_test, how='left', on=['id'])\n",
    "test_ext = test_ext.merge(purch_before, how='left', on=['id'])\n",
    "test_ext.columns = ['id','purch_date', 'prev_purch_date', 'min_date', 'purchases_in_train']\n",
    "test_ext['purch'] = 1 \n",
    "test_ext['cum_purch'] = test_ext.groupby(['id']).purch.cumsum()\n",
    "\n",
    "test_ext['purchases_in_train'].fillna(0, inplace=True) \n",
    "test_ext['frequency'] = test_ext['purchases_in_train'] + test_ext['cum_purch']\n",
    "test_ext['T'] = (test_ext.purch_date-test_ext.min_date).dt.days\n",
    "\n",
    "test_ext['prev_purch_date'] = np.where(test_ext.prev_purch_date.isna(), test_ext.purch_date, test_ext.prev_purch_date)\n",
    "test_ext['recency'] = (test_ext.purch_date-test_ext.prev_purch_date).dt.days\n",
    "test_ext['next_purch_date'] = test_ext.groupby('id')['purch_date'].shift(-1)\n",
    "\n",
    "test_ext = test_ext[['id', 'purch_date', 'next_purch_date', 'frequency', 'T', 'recency']]\n",
    "test_ext = test_ext[~test_ext.next_purch_date.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b957dc13-fe02-47eb-9b78-76b7473f63c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>purch_date</th>\n",
       "      <th>next_purch_date</th>\n",
       "      <th>frequency</th>\n",
       "      <th>T</th>\n",
       "      <th>recency</th>\n",
       "      <th>label_kmeans_10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--GwShaESDOI3t_wT4mmDQ</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>2021-11-07</td>\n",
       "      <td>2.0</td>\n",
       "      <td>524</td>\n",
       "      <td>524</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--MZvNm3Q6mYrohqHxwYsw</td>\n",
       "      <td>2021-09-04</td>\n",
       "      <td>2021-09-22</td>\n",
       "      <td>7.0</td>\n",
       "      <td>432</td>\n",
       "      <td>183</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--MZvNm3Q6mYrohqHxwYsw</td>\n",
       "      <td>2021-09-22</td>\n",
       "      <td>2021-10-03</td>\n",
       "      <td>8.0</td>\n",
       "      <td>450</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--MZvNm3Q6mYrohqHxwYsw</td>\n",
       "      <td>2021-10-03</td>\n",
       "      <td>2021-10-06</td>\n",
       "      <td>9.0</td>\n",
       "      <td>461</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--MZvNm3Q6mYrohqHxwYsw</td>\n",
       "      <td>2021-10-06</td>\n",
       "      <td>2021-10-07</td>\n",
       "      <td>10.0</td>\n",
       "      <td>464</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id  purch_date next_purch_date  frequency    T  \\\n",
       "0  --GwShaESDOI3t_wT4mmDQ  2021-11-04      2021-11-07        2.0  524   \n",
       "1  --MZvNm3Q6mYrohqHxwYsw  2021-09-04      2021-09-22        7.0  432   \n",
       "2  --MZvNm3Q6mYrohqHxwYsw  2021-09-22      2021-10-03        8.0  450   \n",
       "3  --MZvNm3Q6mYrohqHxwYsw  2021-10-03      2021-10-06        9.0  461   \n",
       "4  --MZvNm3Q6mYrohqHxwYsw  2021-10-06      2021-10-07       10.0  464   \n",
       "\n",
       "   recency  label_kmeans_10  \n",
       "0      524                2  \n",
       "1      183                0  \n",
       "2       18                0  \n",
       "3       11                0  \n",
       "4        3                0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_agg = test_ext.merge(cluster, how='left', on='id')\n",
    "test_agg.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78bbbcd-3b24-4ecd-b819-5a79629833ef",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e704819b-22f4-4238-9d82-a58f50a1c516",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pnf = ParetoNBDFitter()\n",
    "# pnf.fit(train_agg['frequency'], train_agg['recency'], train_agg['T'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83da3695-19fc-4dbf-bfa0-a5d36351cf93",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_kmeans_10</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>14102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>16210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>3310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>15380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>17883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label_kmeans_10     id\n",
       "0                0   5494\n",
       "1                1  15417\n",
       "2                2  14102\n",
       "3                3  16210\n",
       "4                4    952\n",
       "5                5   3310\n",
       "6                6     47\n",
       "7                7  15380\n",
       "8                8  17883\n",
       "9                9     17"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_agg.groupby('label_kmeans_10').id.nunique().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "53649ca2-1c3b-40dd-ada4-b3347e894159",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_features = []\n",
    "\n",
    "for i in np.arange(1, 211):\n",
    "    pred_features.append('pred_purch_d'+'{}'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34486375-a33a-4bf4-bda7-b30b9bb9465d",
   "metadata": {},
   "source": [
    "### Cluster 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b38abef8-c5d6-4f3c-8b6f-279d0465a15b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  if sys.path[0] == \"\":\n"
     ]
    }
   ],
   "source": [
    "train_cluster_data = train_agg[train_agg.label_kmeans_10==0]\n",
    "\n",
    "bgf_cluser_0 = BetaGeoFitter(penalizer_coef=0.001)\n",
    "bgf_cluser_0.fit(train_cluster_data['frequency'], train_cluster_data['recency'], train_cluster_data['T'])\n",
    "\n",
    "test_cluster_0 = test_agg[test_agg.label_kmeans_10==0]\n",
    "\n",
    "for i in np.arange(1, 211):\n",
    "    test_cluster_0['pred_purch_d{}'.format(i)] = np.round(bgf_cluser_0.conditional_expected_number_of_purchases_up_to_time(i, \n",
    "                                                                                                                           test_cluster_0['frequency'].values, \n",
    "                                                                                                                           test_cluster_0['recency'].values, \n",
    "                                                                                                                           test_cluster_0['T'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e94856-50a0-4f45-9c0d-c7ec8f496c4b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Cluster 1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "38df8ab2-8a11-4f90-ab18-de71c1426b92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/lib/python3.7/site-packages/lifetimes/fitters/pareto_nbd_fitter.py:216: RuntimeWarning: invalid value encountered in logaddexp\n",
      "  A_2 = logaddexp(-(r + x) * log(alpha + T) - s * log(beta + T), log(s) + log_A_0 - log(r_s_x))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lifetimes.ParetoNBDFitter: fitted with 15417 subjects, alpha: 0.00, beta: 0.00, r: 0.89, s: 4.84>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_cluster_data = train_agg[train_agg.label_kmeans_10==1]\n",
    "\n",
    "\n",
    "bgf_cluser_1 = ParetoNBDFitter(penalizer_coef=0.001)\n",
    "bgf_cluser_1.fit(train_cluster_data['frequency'], train_cluster_data['recency'], train_cluster_data['T'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58825e0c-bd16-4b67-8091-57183dfdecc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:7: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "test_cluster_1 = test_agg[test_agg.label_kmeans_10==1]\n",
    "\n",
    "for i in np.arange(1, 211):\n",
    "    test_cluster_1['pred_purch_d{}'.format(i)] = np.round(bgf_cluser_1.conditional_expected_number_of_purchases_up_to_time(i, \n",
    "                                                                                                                           test_cluster_1['frequency'].values, \n",
    "                                                                                                                           test_cluster_1['recency'].values, \n",
    "                                                                                                                           test_cluster_1['T'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9217b3c2-32ec-4f53-b3a8-82c2776b4ef6",
   "metadata": {},
   "source": [
    "### Cluster 2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "daa62eec-2da1-4bcd-b283-58ea33e65b30",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  if sys.path[0] == \"\":\n"
     ]
    }
   ],
   "source": [
    "train_cluster_data = train_agg[train_agg.label_kmeans_10==2]\n",
    "\n",
    "bgf_cluser_2 = BetaGeoFitter(penalizer_coef=0.001)\n",
    "bgf_cluser_2.fit(train_cluster_data['frequency'], train_cluster_data['recency'], train_cluster_data['T'])\n",
    "\n",
    "test_cluster_2 = test_agg[test_agg.label_kmeans_10==2]\n",
    "\n",
    "for i in np.arange(1, 211):\n",
    "    test_cluster_2['pred_purch_d{}'.format(i)] = np.round(bgf_cluser_2.conditional_expected_number_of_purchases_up_to_time(i, \n",
    "                                                                                                                           test_cluster_2['frequency'].values, \n",
    "                                                                                                                           test_cluster_2['recency'].values, \n",
    "                                                                                                                           test_cluster_2['T'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5808ba4-e74f-4fc8-8dc2-7fbfa395d022",
   "metadata": {},
   "source": [
    "### Cluster 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a8f7f33-55f2-4ea9-9f34-08633808b6f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  if sys.path[0] == \"\":\n"
     ]
    }
   ],
   "source": [
    "train_cluster_data = train_agg[train_agg.label_kmeans_10==3]\n",
    "\n",
    "bgf_cluser_3 = BetaGeoFitter(penalizer_coef=0.001)\n",
    "bgf_cluser_3.fit(train_cluster_data['frequency'], train_cluster_data['recency'], train_cluster_data['T'])\n",
    "\n",
    "test_cluster_3 = test_agg[test_agg.label_kmeans_10==3]\n",
    "\n",
    "for i in np.arange(1, 211):\n",
    "    test_cluster_3['pred_purch_d{}'.format(i)] = np.round(bgf_cluser_3.conditional_expected_number_of_purchases_up_to_time(i, \n",
    "                                                                                                                           test_cluster_3['frequency'].values, \n",
    "                                                                                                                           test_cluster_3['recency'].values, \n",
    "                                                                                                                           test_cluster_3['T'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6398b08-eb7d-4e7d-b5cb-1ca8601eae6d",
   "metadata": {},
   "source": [
    "### Cluster 4,5,6,9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b3d211ee-ce47-48eb-8265-9a9e60266bbe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  if sys.path[0] == \"\":\n"
     ]
    }
   ],
   "source": [
    "train_cluster_data = train_agg[train_agg.label_kmeans_10.isin([4,5,6,9])]\n",
    "\n",
    "bgf_cluser_4 = ParetoNBDFitter(penalizer_coef=0.001)\n",
    "bgf_cluser_4.fit(train_cluster_data['frequency'], train_cluster_data['recency'], train_cluster_data['T'])\n",
    "\n",
    "test_cluster_4 = test_agg[test_agg.label_kmeans_10.isin([4,5,6,9])]\n",
    "\n",
    "for i in np.arange(1, 211):\n",
    "    test_cluster_4['pred_purch_d{}'.format(i)] = np.round(bgf_cluser_4.conditional_expected_number_of_purchases_up_to_time(i, \n",
    "                                                                                                                           test_cluster_4['frequency'].values, \n",
    "                                                                                                                           test_cluster_4['recency'].values, \n",
    "                                                                                                                           test_cluster_4['T'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4adec4af-983c-4c44-87dc-9f04c878e3d9",
   "metadata": {},
   "source": [
    "### Cluster 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3a21f71a-e230-4708-ba08-ccd08442428c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/numpy/core/fromnumeric.py:86: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n",
      "/opt/conda/lib/python3.7/site-packages/lifetimes/fitters/pareto_nbd_fitter.py:216: RuntimeWarning: invalid value encountered in logaddexp\n",
      "  A_2 = logaddexp(-(r + x) * log(alpha + T) - s * log(beta + T), log(s) + log_A_0 - log(r_s_x))\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  if sys.path[0] == \"\":\n"
     ]
    }
   ],
   "source": [
    "train_cluster_data = train_agg[train_agg.label_kmeans_10==7]\n",
    "\n",
    "bgf_cluser_7 = ParetoNBDFitter(penalizer_coef=0.001)\n",
    "bgf_cluser_7.fit(train_cluster_data['frequency'], train_cluster_data['recency'], train_cluster_data['T'])\n",
    "\n",
    "test_cluster_7 = test_agg[test_agg.label_kmeans_10==7]\n",
    "\n",
    "for i in np.arange(1, 211):\n",
    "    test_cluster_7['pred_purch_d{}'.format(i)] = np.round(bgf_cluser_7.conditional_expected_number_of_purchases_up_to_time(i, \n",
    "                                                                                                                           test_cluster_7['frequency'].values, \n",
    "                                                                                                                           test_cluster_7['recency'].values, \n",
    "                                                                                                                           test_cluster_7['T'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00061046-8e37-42f4-becf-f424b3d1aa18",
   "metadata": {},
   "source": [
    "### Cluster 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e2da8282-3390-42da-9b2b-293d0d592d79",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:12: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  if sys.path[0] == \"\":\n"
     ]
    }
   ],
   "source": [
    "train_cluster_data = train_agg[train_agg.label_kmeans_10==8]\n",
    "\n",
    "bgf_cluser_8 = BetaGeoFitter(penalizer_coef=0.001)\n",
    "bgf_cluser_8.fit(train_cluster_data['frequency'], train_cluster_data['recency'], train_cluster_data['T'])\n",
    "\n",
    "test_cluster_8 = test_agg[test_agg.label_kmeans_10==8]\n",
    "\n",
    "for i in np.arange(1, 211):\n",
    "    test_cluster_8['pred_purch_d{}'.format(i)] = np.round(bgf_cluser_8.conditional_expected_number_of_purchases_up_to_time(i, \n",
    "                                                                                                                           test_cluster_8['frequency'].values, \n",
    "                                                                                                                           test_cluster_8['recency'].values, \n",
    "                                                                                                                           test_cluster_8['T'].values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17a5caa-c2d8-402e-ae53-d073e9a3935e",
   "metadata": {},
   "source": [
    "## Evaluate error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c5d58955-41c1-4afb-91a9-32f0b11bba81",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_cluster_data = pd.concat([test_cluster_0,test_cluster_1,test_cluster_2,test_cluster_3, test_cluster_4, test_cluster_7, test_cluster_8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0de36e97-b83a-4b4a-8ac6-cde1fd208b1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/pandas/core/arrays/datetimelike.py:1190: PerformanceWarning: Adding/subtracting object-dtype array to TimedeltaArray not vectorized\n",
      "  PerformanceWarning,\n"
     ]
    }
   ],
   "source": [
    "test_cluster_data_long = pd.melt(test_cluster_data, id_vars=['id', 'purch_date', 'next_purch_date'], value_vars=pred_features)\n",
    "test_cluster_data_long['day'] = test_cluster_data_long.variable.str.replace('\\D+', '')\n",
    "test_cluster_data_long = test_cluster_data_long[test_cluster_data_long['value']==1].groupby(['id', 'purch_date', 'next_purch_date']).day.min().reset_index()\n",
    "\n",
    "\n",
    "test_prediction = test_cluster_data[['id', 'purch_date', 'next_purch_date']].merge(test_cluster_data_long[['id', 'purch_date','day']], how='left', on=['id', 'purch_date'])\n",
    "test_prediction = test_prediction[~test_prediction.next_purch_date.isna()]\n",
    "test_prediction['day'] = np.where(test_prediction.day.isna(), 210, test_prediction.day)\n",
    "test_prediction['next_date_pred'] = test_prediction['purch_date'] + pd.to_timedelta(pd.np.ceil(test_prediction['day'].astype(int)), unit=\"D\") \n",
    "test_prediction['difr'] = abs((test_prediction['next_purch_date'] - test_prediction['next_date_pred']).dt.days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d3cc091d-ca03-41e7-96cc-9a64308aa891",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "169.61778244367278"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prediction.difr.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
